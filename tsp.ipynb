{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import time\n",
    "from itertools import combinations\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsp_file(file_path):\n",
    "    edge_weight_section = []\n",
    "    is_edge_weight_section = False\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove extra whitespace\n",
    "            \n",
    "            if line.startswith(\"DIMENSION\"):\n",
    "                num_cities = int(line.split(\":\")[1].strip())\n",
    "                print(f\"Number of cities: {num_cities}\")\n",
    "                continue\n",
    "            \n",
    "            if line.startswith(\"EDGE_WEIGHT_SECTION\"):\n",
    "                is_edge_weight_section = True\n",
    "                continue\n",
    "            \n",
    "            if line.startswith(\"EDGE_WEIGHT_FORMAT\"):\n",
    "                format = line.split(\":\")[1].strip()\n",
    "                # print(f\"Edge weight format: {format}\")\n",
    "                continue\n",
    "\n",
    "            if is_edge_weight_section:\n",
    "                if line == \"EOF\" or line == 'DISPLAY_DATA_SECTION':  # Stop reading if end of file marker is found\n",
    "                    break\n",
    "\n",
    "                # Add numbers from the line to the edge_weight_section list\n",
    "                edge_weight_section.extend(map(int, line.split()))\n",
    "\n",
    "    return edge_weight_section, num_cities, format\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSP with OR tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_tsp_with_ortools(distance_dict, num_cities):\n",
    "    \"\"\"\n",
    "    Solve TSP using Google OR-Tools\n",
    "    \n",
    "    Args:\n",
    "        distance_dict: Dictionary with (i,j) tuples as keys and distances as values\n",
    "        num_cities: Number of cities in the problem\n",
    "    \n",
    "    Returns:\n",
    "        route: List of cities in optimal order\n",
    "        total_distance: Total distance of the optimal route\n",
    "    \"\"\"\n",
    "    # Create the routing model\n",
    "    manager = pywrapcp.RoutingIndexManager(num_cities, 1, 0)\n",
    "    routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "    # Create and register a transit callback\n",
    "    def distance_callback(from_index, to_index):\n",
    "        \"\"\"Returns the distance between the two nodes.\"\"\"\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        \n",
    "        # Convert to 1-based indexing to match your distance_dict\n",
    "        from_node += 1\n",
    "        to_node += 1\n",
    "        \n",
    "        # Check both orderings since we might have only half the matrix\n",
    "        if (from_node, to_node) in distance_dict:\n",
    "            return distance_dict[(from_node, to_node)]\n",
    "        elif (to_node, from_node) in distance_dict:\n",
    "            return distance_dict[(to_node, from_node)]\n",
    "        return 0  # Should not happen if distance_dict is complete\n",
    "\n",
    "    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n",
    "\n",
    "    # Define cost of each arc\n",
    "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
    "\n",
    "    # Setting first solution heuristic (cheapest addition)\n",
    "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    search_parameters.first_solution_strategy = (\n",
    "        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n",
    "    \n",
    "    # Set metaheuristic\n",
    "    search_parameters.local_search_metaheuristic = (\n",
    "        routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH)\n",
    "    \n",
    "    # Set time limit\n",
    "    search_parameters.time_limit.FromSeconds(10)\n",
    "\n",
    "    # Solve the problem\n",
    "    solution = routing.SolveWithParameters(search_parameters)\n",
    "\n",
    "    if solution:\n",
    "        # Extract the route\n",
    "        route = []\n",
    "        total_distance = 0\n",
    "        index = routing.Start(0)\n",
    "        \n",
    "        while not routing.IsEnd(index):\n",
    "            node = manager.IndexToNode(index)\n",
    "            route.append(node + 1)  # Convert back to 1-based indexing\n",
    "            previous_index = index\n",
    "            index = solution.Value(routing.NextVar(index))\n",
    "            total_distance += routing.GetArcCostForVehicle(previous_index, index, 0)\n",
    "        \n",
    "        # Add the final node to complete the tour\n",
    "        route.append(route[0])\n",
    "        \n",
    "        return route, total_distance\n",
    "    else:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to create a dictionary with the distances between the cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lower triangular matrix\n",
    "def create_distance_dict_lower_diag_row(edge_weight_section, num_cities):\n",
    "    distance_dict = {}\n",
    "    idx = 0  # To track position in the edge_weight_section\n",
    "\n",
    "    # Iterate through lower triangular matrix\n",
    "    for i in range(1, num_cities+1):\n",
    "        for j in range(1, i+1):\n",
    "            if i != j:  # Ignore the diagonal elements (distances between same cities)\n",
    "                distance_dict[(i, j)] = edge_weight_section[idx]\n",
    "            idx += 1\n",
    "\n",
    "    return distance_dict\n",
    "\n",
    "\n",
    "# Upper triangular matrix\n",
    "def create_distance_dict_upper_diag_row(edge_weight_section, num_cities):\n",
    "    distance_dict = {}\n",
    "    index = 0  # To keep track of the position in the edge_weight_section\n",
    "\n",
    "    # Loop through each city `i`\n",
    "    for i in range(num_cities):\n",
    "        # For each city `i`, iterate over `j` from `i` to `num_cities` (inclusive of diagonal)\n",
    "        for j in range(i, num_cities):\n",
    "            if i != j:  # Ignore diagonal (i == j) if needed\n",
    "                distance_dict[(i + 1, j + 1)] = edge_weight_section[index]\n",
    "            index += 1\n",
    "\n",
    "    return distance_dict\n",
    "\n",
    "def create_distance_dict_full_matrix(edge_weight_section, num_cities):\n",
    "    distance_dict = {}\n",
    "    index = 0  # To keep track of the position in the edge_weight_section\n",
    "\n",
    "    # Loop through each city `i`\n",
    "    for i in range(num_cities):\n",
    "        # For each city `i`, iterate over all cities `j`\n",
    "        for j in range(i, num_cities):\n",
    "            if i != j:  # Ignore diagonal (i == j) if needed\n",
    "                distance_dict[(i + 1, j + 1)] = edge_weight_section[index]\n",
    "            index += 1\n",
    "        index += i + 1\n",
    "\n",
    "    return distance_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions for blossom cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_blossom_cuts(graph, x_vals, tolerance=0):\n",
    "    \"\"\"\n",
    "    Find blossom inequalities by:\n",
    "    1. Finding cyclic subgraphs with fractional values\n",
    "    2. Checking edges going out of these cycles\n",
    "    3. Identifying cycles with odd number of outgoing edges with value 1\n",
    "    \n",
    "    Args:\n",
    "        graph: NetworkX graph\n",
    "        x_vals: Dictionary of edge values from LP solution {(u,v): value}\n",
    "        tolerance: Tolerance for considering a value fractional or 1\n",
    "    \"\"\"\n",
    "    def is_fractional(val):\n",
    "        return tolerance < val < 1 - tolerance\n",
    "    \n",
    "    def is_one(val):\n",
    "        return abs(val - 1.0) < tolerance\n",
    "    \n",
    "    def find_fractional_cycles():\n",
    "        \"\"\"Find all cycles in the graph that consist of fractional edges\"\"\"\n",
    "        # Create subgraph with only fractional edges\n",
    "        fractional_edges = [(u, v) for (u, v), val in x_vals.items() \n",
    "                          if is_fractional(val)]\n",
    "        frac_graph = nx.Graph(fractional_edges)\n",
    "        # print(frac_graph)\n",
    "        \n",
    "        # Find all cycles in the fractional graph\n",
    "        cycles = []\n",
    "        try:\n",
    "            cycles = nx.cycle_basis(frac_graph)\n",
    "        except nx.NetworkXNoCycle:\n",
    "            pass\n",
    "        return cycles\n",
    "    \n",
    "    def get_outgoing_edges(cycle_nodes):\n",
    "        \"\"\"Get all edges that have exactly one endpoint in the cycle\"\"\"\n",
    "        cycle_set = set(cycle_nodes)\n",
    "        outgoing = []\n",
    "        \n",
    "        # Check all edges in the original graph\n",
    "        for (u, v), val in x_vals.items():\n",
    "            u_in = u in cycle_set\n",
    "            v_in = v in cycle_set\n",
    "            if u_in != v_in:  # Exactly one endpoint in cycle\n",
    "                outgoing.append((u, v, val))\n",
    "                \n",
    "        return outgoing\n",
    "    \n",
    "    def count_unit_edges(edges):\n",
    "        \"\"\"Count edges that have value 1\"\"\"\n",
    "        return sum(1 for _, _, val in edges if is_one(val))\n",
    "    \n",
    "    blossoms = []\n",
    "    \n",
    "    # Step 1: Find all cycles with fractional values\n",
    "    fractional_cycles = find_fractional_cycles()\n",
    "    \n",
    "    # Step 2: For each cycle, check outgoing edges\n",
    "    for cycle in fractional_cycles:\n",
    "        # Get all edges going out of the cycle\n",
    "        outgoing_edges = get_outgoing_edges(cycle)\n",
    "        \n",
    "        # Count edges with value 1\n",
    "        unit_edges_count = count_unit_edges(outgoing_edges)\n",
    "        \n",
    "        # If odd number of unit edges, we've found a blossom\n",
    "        if unit_edges_count % 2 == 1:\n",
    "            # Store the handle (cycle) and teeth (unit edges)\n",
    "            teeth = [(u, v) for u, v, val in outgoing_edges if is_one(val)]\n",
    "            blossoms.append({\n",
    "                'handle': cycle,\n",
    "                'teeth': teeth,\n",
    "                'num_teeth': unit_edges_count\n",
    "            })\n",
    "    \n",
    "    return blossoms\n",
    "\n",
    "def get_delta_edges(node_set, all_edges):\n",
    "        \"\"\"Get edges with exactly one endpoint in the given set\"\"\"\n",
    "        delta_edges = []\n",
    "        node_set = set(node_set)\n",
    "        for i, j in all_edges:\n",
    "            i_in = i in node_set\n",
    "            j_in = j in node_set\n",
    "            if i_in != j_in:  # Exactly one endpoint in set\n",
    "                delta_edges.append((i, j))\n",
    "        return delta_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function for connectivity cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtour function\n",
    "def subtour(edges):\n",
    "    unvisited = list(range(1, num_cities+1))\n",
    "    cycle = range(num_cities+1)  # initial length has 1 more city\n",
    "    while unvisited:  # true if list is non-empty\n",
    "        thiscycle = []\n",
    "        neighbors = unvisited\n",
    "        while neighbors:\n",
    "            current = neighbors[0]\n",
    "            thiscycle.append(current)\n",
    "            unvisited.remove(current)\n",
    "            neighbors = [j for i, j in edges.select(current, '*') if j in unvisited]\n",
    "        if len(cycle) > len(thiscycle):\n",
    "            cycle = thiscycle\n",
    "    return cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function for 2 connected graph cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_min_cut_flow_from_one(selected_edges, edge_weights, num_nodes):\n",
    "    \"\"\"\n",
    "    Check if the graph has any cuts with flow less than 2 from node 1 to all other nodes.\n",
    "    Parameters:\n",
    "        selected_edges: list of edges selected in the current solution\n",
    "        edge_weights: dictionary with edge weights from vals\n",
    "        num_nodes: total number of nodes in the graph\n",
    "    Returns:\n",
    "            - has_cut_less_than_2: boolean indicating if there's a cut < 2\n",
    "            - cut_value: the value of the minimum cut found\n",
    "            - cut_partition: the nodes in the smaller partition of the cut\n",
    "            - violating_sink: the sink node causing the violation\n",
    "    \"\"\"\n",
    "    # Create NetworkX graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(1, num_nodes + 1))\n",
    "    \n",
    "    # Add selected edges with their weights\n",
    "    for i, j in selected_edges:\n",
    "        weight = edge_weights[i, j]\n",
    "        if weight > 1e-3:  # Only consider edges with significant weight\n",
    "            G.add_edge(i, j, capacity=weight)\n",
    "    \n",
    "    min_cut_value = float('inf')\n",
    "    min_cut_partition = None\n",
    "    violating_sink = None\n",
    "    \n",
    "    # Check min cut from node 1 to all other nodes\n",
    "    source = 1\n",
    "    for sink in range(2, num_nodes + 1):\n",
    "        try:\n",
    "            cut_value, partition = nx.minimum_cut(G, source, sink)\n",
    "            \n",
    "            if cut_value < min_cut_value:\n",
    "                min_cut_value = cut_value\n",
    "                min_cut_partition = partition\n",
    "                violating_sink = sink\n",
    "        except nx.NetworkXError:\n",
    "            return True, 0, {source}, sink\n",
    "    \n",
    "    return (min_cut_value < (2), min_cut_value, \n",
    "            set(min_cut_partition[0]) if min_cut_partition else None,\n",
    "            violating_sink)\n",
    "\n",
    "def validate_connectivity_from_one(selected_edges, edge_weights, num_nodes):\n",
    "    \"\"\"\n",
    "    Validate if the graph has sufficient connectivity from node 1.\n",
    "    Parameters:\n",
    "        selected_edges: list of edges selected in the current solution\n",
    "        edge_weights: dictionary with edge weights from vals\n",
    "        num_nodes: Total number of nodes\n",
    "    Returns:\n",
    "            - is_valid: boolean indicating if connectivity requirement is met\n",
    "            - cut_info: details about the violating cut if found\n",
    "    \"\"\"\n",
    "    has_small_cut, cut_value, cut_partition, violating_sink = check_min_cut_flow_from_one(selected_edges, edge_weights, num_nodes)\n",
    "    \n",
    "    if has_small_cut:\n",
    "        cut_info = {\n",
    "            'cut_value': cut_value,\n",
    "            'partition1': cut_partition,\n",
    "            'partition2': set(range(1, num_nodes + 1)) - cut_partition,\n",
    "            'violating_sink': violating_sink\n",
    "        }\n",
    "        # print(\"cut_info\", cut_info)\n",
    "        return False, cut_info\n",
    "    \n",
    "    return True, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to add conncetivity cuts, 2 connected cuts, blossom cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtourelim_with_blossom_and_2connected_cuts(model, where):\n",
    "    global num_cities, lazy_cut_count, user_cut_count\n",
    "\n",
    "    if where == GRB.Callback.MIPNODE:\n",
    "        if model.cbGet(GRB.Callback.MIPNODE_STATUS) == GRB.OPTIMAL:\n",
    "            # Get solution at integer feasible solution\n",
    "            vals = model.cbGetNodeRel(model._vars)\n",
    "            selected = gp.tuplelist((i, j) for i, j in model._vars.keys() if vals[i, j] > 1e-3)\n",
    "            edge_weights = {(i, j): vals[i, j] for i, j in selected}\n",
    "            # Find the shortest cycle in the selected edge list\n",
    "            tour = subtour(selected)\n",
    "            if len(tour) < num_cities:\n",
    "                # Add subtour elimination constraint if the tour is incomplete\n",
    "                model.cbLazy(gp.quicksum(model._vars[i, j] for i, j in combinations(tour, 2)) <= len(tour) - 1)\n",
    "                lazy_cut_count += 1\n",
    "\n",
    "            else:\n",
    "                # Check for 2-connected cuts\n",
    "                is_valid, cut_info = validate_connectivity_from_one(selected, edge_weights, num_cities)\n",
    "                \n",
    "                if not is_valid:\n",
    "                    cut_partition = cut_info['partition1']\n",
    "                    model.cbLazy(gp.quicksum(model._vars[i, j] for i, j in combinations(cut_partition, 2) \n",
    "                                             if (i, j) in model._vars.keys()) <= len(cut_partition) - 1)\n",
    "                    lazy_cut_count += 1\n",
    "                    # print(2)\n",
    "\n",
    "                # Check for blossom constraints\n",
    "                else:\n",
    "                    graph = nx.Graph()\n",
    "                    graph.add_edges_from(selected)\n",
    "                    blossoms = find_blossom_cuts(graph, edge_weights)\n",
    "                    # print(f\"Found {len(blossoms)} blossoms\")\n",
    "                    \n",
    "                    for blossom in blossoms:\n",
    "                        handle = blossom['handle']\n",
    "                        teeth = blossom['teeth']\n",
    "                        k = len(teeth)\n",
    "\n",
    "                        expr = 0\n",
    "                        all_edges = list(model._vars.keys())\n",
    "\n",
    "                        # Calculate x(δ(H)) for handle\n",
    "                        handle_delta = get_delta_edges(handle, all_edges)\n",
    "                        for i, j in handle_delta:\n",
    "                            if (i, j) in model._vars:\n",
    "                                expr += model._vars[i, j]\n",
    "\n",
    "                        # Calculate sum(x(δ(T_i))) for each tooth\n",
    "                        for tooth in teeth:\n",
    "                            tooth_endpoints = set([tooth[0], tooth[1]])\n",
    "                            tooth_delta = get_delta_edges(tooth_endpoints, all_edges)\n",
    "                            for i, j in tooth_delta:\n",
    "                                if (i, j) in model._vars:\n",
    "                                    expr += model._vars[i, j]\n",
    "\n",
    "                        # Add blossom constraint: x(δ(H)) + sum(x(δ(T_i))) ≥ 3k + 1\n",
    "                        model.cbCut(expr >= 3 * k + 1)\n",
    "                        user_cut_count += 1\n",
    "    elif where == GRB.callback.MIPSOL:\n",
    "        vals = model.cbGetSolution(model._vars)\n",
    "        selected = gp.tuplelist((i, j) for i, j in model._vars.keys() if vals[i, j] > 1e-3)\n",
    "        tour = subtour(selected)\n",
    "        if len(tour) < num_cities:\n",
    "            # Add subtour elimination constraint if the tour is incomplete\n",
    "            model.cbLazy(gp.quicksum(model._vars[i, j] for i, j in combinations(tour, 2)) <= len(tour) - 1)\n",
    "            lazy_cut_count += 1\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call functions to read data, create distance dictionary, create gurobi model, and solve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read and process the TSP instance, set up the model, and solve it\n",
    "def solve_tsp_instance(file_path, total_time_limit=120):\n",
    "    global lazy_cut_count, user_cut_count, num_cities\n",
    "\n",
    "    # Step 1: Read and process the TSP file, and record the time taken\n",
    "    start_time = time.time()\n",
    "    edge_weight_section, num_cities, format = read_tsp_file(file_path)\n",
    "    \n",
    "    # Initialize distance dictionary based on format\n",
    "    if format == 'UPPER_DIAG_ROW':\n",
    "        distance_dict = create_distance_dict_upper_diag_row(edge_weight_section, num_cities)\n",
    "    elif format == 'LOWER_DIAG_ROW':\n",
    "        distance_dict = create_distance_dict_lower_diag_row(edge_weight_section, num_cities)\n",
    "    elif format == 'FULL_MATRIX':\n",
    "        distance_dict = create_distance_dict_full_matrix(edge_weight_section, num_cities)\n",
    "    \n",
    "    matrix_creation_time = time.time() - start_time\n",
    "\n",
    "    # Calculate remaining time for solving\n",
    "    remaining_time = total_time_limit - matrix_creation_time\n",
    "    if remaining_time <= 0:\n",
    "        print(\"Matrix creation exceeded total time limit. Skipping instance.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Initialize Gurobi model\n",
    "    m = gp.Model()\n",
    "    m.setParam(GRB.Param.OutputFlag, 0)\n",
    "    m.setParam(GRB.Param.Cuts, 0)\n",
    "    m.setParam(GRB.Param.Heuristics, 0.0)\n",
    "    m.setParam(GRB.Param.Presolve, 0)\n",
    "    m.setParam(GRB.Param.TimeLimit, remaining_time)\n",
    "    m.setParam('MIPGap', 0.0)  # Set MIP gap tolerance\n",
    "    # Step 3: Define variables and constraints\n",
    "    vars = m.addVars(distance_dict.keys(), obj=distance_dict, vtype=GRB.BINARY, name='x')\n",
    "    vars.update({(j, i): vars[i, j] for i, j in vars.keys()})\n",
    "    m.addConstrs(vars.sum(i, '*') == 2 for i in range(1, num_cities + 1))\n",
    "    m._vars = vars\n",
    "    m.Params.lazyConstraints = 1\n",
    "    \n",
    "    # Step 4: write lp file\n",
    "    m.write('model.lp')\n",
    "    \n",
    "    # Step 5: copy model for solving without cuts\n",
    "    model_without_cuts = m.copy()\n",
    "\n",
    "\n",
    "    lazy_cut_count = 0\n",
    "    user_cut_count = 0\n",
    "    solve_start_time = time.time()\n",
    "    m.optimize(subtourelim_with_blossom_and_2connected_cuts)\n",
    "    solve_time = time.time() - solve_start_time\n",
    "\n",
    "    # Step 6: Collect statistics\n",
    "    best_lp_bound = m.ObjBound\n",
    "    best_ip_solution = m.ObjVal\n",
    "    nodes_explored = m.NodeCount\n",
    "    gap = m.MIPGap\n",
    "\n",
    "    # Step 7: Optimize without lazy cuts\n",
    "    model_without_cuts.optimize()\n",
    "    best_ip_solution_no_cuts = model_without_cuts.ObjVal\n",
    "    # print(f\"Best IP Solution without user/lazy cuts: {best_ip_solution_no_cuts}\")\n",
    "\n",
    "    \n",
    "    # Step 8: OR-tools solution\n",
    "    route, total_distance = solve_tsp_with_ortools(distance_dict, num_cities)\n",
    "    \n",
    "    # Step 9: Prepare result dictionary\n",
    "    result = {\n",
    "        \"Problem Class\": \"STSP\",\n",
    "        \"Instance\": os.path.basename(file_path),\n",
    "        \"Best LP Bound\": best_lp_bound,\n",
    "        \"Best IP solution with cuts\": best_ip_solution,\n",
    "        \"Best IP solution without user/lazy cuts\": best_ip_solution_no_cuts,\n",
    "        \"Nodes explored (with cuts)\": nodes_explored,\n",
    "        \"User cuts added\": user_cut_count,\n",
    "        \"Lazy cuts added\": lazy_cut_count,\n",
    "        \"GAP\": gap,\n",
    "        \"Time\": solve_time + matrix_creation_time,\n",
    "        \"Google OR-tools solution\": total_distance\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    results = []  # Initialize an empty list to store each result\n",
    "    for root, dirs, files in os.walk(\"STSP\"):\n",
    "        files = sorted(files)\n",
    "        for file in files:\n",
    "            # if file.startswith(\"da\"):\n",
    "                print(f\"----------------{file}----------------\")\n",
    "                result = solve_tsp_instance(os.path.join(root, file))\n",
    "                if result:\n",
    "                    results.append(result)  # Append each result dictionary to the list\n",
    "    \n",
    "    # Create a pandas DataFrame from the results list and save to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('tsp_results.csv', index=False)\n",
    "    print(\"Results saved to tsp_results.csv\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------dantzig42.tsp----------------\n",
      "Number of cities: 42\n",
      "Results saved to tsp_results.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplexenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
